{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08dafd87",
   "metadata": {},
   "source": [
    "## Replicating layer-wise and family-wise analysis on an English dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66550e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # makes figs nicer!\n",
    "\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid',font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc552e",
   "metadata": {},
   "source": [
    "### define useful custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "045d2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define useful custom functions to ...\n",
    "\n",
    "### ... find the target tokens within tokenized sequence\n",
    "def find_sublist_index(mylist, sublist):\n",
    "    \"\"\"Find the first occurence of sublist in list.\n",
    "    Return the start and end indices of sublist in list\"\"\"\n",
    "\n",
    "    for i in range(len(mylist)):\n",
    "        if mylist[i] == sublist[0] and mylist[i:i+len(sublist)] == sublist:\n",
    "            return i, i+len(sublist)\n",
    "    return None\n",
    "\n",
    "@functools.lru_cache(maxsize=None)  # This will cache results, handy later...\n",
    "\n",
    "\n",
    "### ... grab the embeddings for your target tokens\n",
    "def get_embedding(model, tokenizer, sentence, target, layer, device):\n",
    "    \"\"\"Get a token embedding for target in sentence\"\"\"\n",
    "    \n",
    "    # Tokenize sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Tokenize target\n",
    "    target_enc = tokenizer.encode(target, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=False).to(device)\n",
    "    \n",
    "    # Get indices of target in input tokens\n",
    "    target_inds = find_sublist_index(\n",
    "        inputs[\"input_ids\"][0].tolist(),\n",
    "        target_enc[0].tolist()\n",
    "    )\n",
    "\n",
    "    # Run model\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        hidden_states = output.hidden_states\n",
    "\n",
    "    # Get layer\n",
    "    selected_layer = hidden_states[layer][0]\n",
    "\n",
    "    #grab just the embeddings for your target word's token(s)\n",
    "    token_embeddings = selected_layer[target_inds[0]:target_inds[1]]\n",
    "\n",
    "    #if a word is represented by >1 tokens, take mean\n",
    "    #across the multiple tokens' embeddings\n",
    "    embedding = torch.mean(token_embeddings, dim=0)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "### ... grab the number of trainable parameters in the model\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"credit: https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\"\"\"\n",
    "    \n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        \n",
    "        # if the param is not trainable, skip it\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        \n",
    "        # otherwise, count it towards your number of params\n",
    "        params = parameter.numel()\n",
    "        total_params += params\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "    return total_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059045c8",
   "metadata": {},
   "source": [
    "### load the dataframe of sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f466cb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimpath = \"../data/extra/rawc_stimuli.csv\"\n",
    "df = pd.read_csv(stimpath)\n",
    "\n",
    "df.shape[0] # number of sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14e4556-415d-4fd8-8bf1-7831d29e6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>same</th>\n",
       "      <th>ambiguity_type</th>\n",
       "      <th>Class</th>\n",
       "      <th>mean_relatedness</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>act</td>\n",
       "      <td>It was a desperate act.</td>\n",
       "      <td>It was a magic act.</td>\n",
       "      <td>False</td>\n",
       "      <td>Polysemy</td>\n",
       "      <td>N</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act</td>\n",
       "      <td>It was a desperate act.</td>\n",
       "      <td>It was a comedic act.</td>\n",
       "      <td>False</td>\n",
       "      <td>Polysemy</td>\n",
       "      <td>N</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>act</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word                sentence1              sentence2   same ambiguity_type  \\\n",
       "0  act  It was a desperate act.    It was a magic act.  False       Polysemy   \n",
       "1  act  It was a desperate act.  It was a comedic act.  False       Polysemy   \n",
       "\n",
       "  Class  mean_relatedness string  \n",
       "0     N          2.181818    act  \n",
       "1     N          2.000000    act  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afeac0",
   "metadata": {},
   "source": [
    "### load your models and tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3179d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the url paths to download your desired models\n",
    "#.  from Hugging Face\n",
    "\n",
    "MODELS = [\"bert-base-uncased\",\n",
    "          \"bert-base-cased\",\n",
    "          \"FacebookAI/xlm-roberta-base\",\n",
    "          \"albert/albert-base-v1\",\n",
    "          \"albert/albert-base-v2\",\n",
    "          ### Tiny?\n",
    "          \"albert/albert-large-v2\",\n",
    "          \"albert/albert-xlarge-v2\",\n",
    "          \"albert/albert-xxlarge-v2\",\n",
    "          \"FacebookAI/roberta-base\",\n",
    "          \"FacebookAI/roberta-large\",\n",
    "          \"distilbert/distilbert-base-uncased\",\n",
    "          \"google-bert/bert-base-multilingual-cased\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317198f1",
   "metadata": {},
   "source": [
    "### compute cosine distances\n",
    "\n",
    "for each target word within a pair of sentences, for each model layer, for each model specified in the `MODELS` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5233c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27810dbeaadd455b948ef686e976c8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639afe4edabb46eebdedbc2edc664f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a36762503c49ef9ad1b535d1d84e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb520e02122490f980343892747ed0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2622edd250ab47a8bb6eca6f4232b663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446150e9c044409f9b05baa59c49d9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 12\n",
      "Total Trainable Params: 177853440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4fb41e492643bbaf541f76e12c5a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f354a232fb234999a1c642618d6eb403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead0db35fa624c3ab31ba751690335ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1444041b004742aea41b2b5e03685bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d131b08179a4050b5bf5984d6c0c423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e254467262814324a227f1921f0f56f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a89d7dd09c4fa9b0e1ddf40b983eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92e20549c7146a4916498195ab80d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79f8f86fb7544dab2d54ef98d57ec98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6774e65876f4e0ba9a8c579ff774f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aea73bb4d34450966bb625c1f759b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d3f0987cf04eff949b52251fe4fa7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3d145efb8543159659f83e2ccd68f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Iterate over models and do the work! \n",
    "\n",
    "for mpath in tqdm(MODELS,colour=\"cornflowerblue\"):\n",
    "\n",
    "    ### Decide which device you want the models to run in\n",
    "    \n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    ### Load your model & tokenizer\n",
    "    \n",
    "    model = transformers.AutoModel.from_pretrained(mpath,output_hidden_states=True)\n",
    "    model.to(device) # allocate model to desired device\n",
    "\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(mpath)  \n",
    "    \n",
    "    \n",
    "    ### Get the number of layers & params directly from the model specifications\n",
    "    \n",
    "    # TODO: Double-check for all configurations\n",
    "    \n",
    "    n_layers = model.config.num_hidden_layers\n",
    "    print(\"number of layers:\", n_layers)\n",
    "\n",
    "    n_params = count_parameters(model)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for layer in range(n_layers+1): # `range` is non-inclusive for the last value of interval\n",
    "        for (ix, row) in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "            ### Get embeddings for S1 and S2\n",
    "\n",
    "            # note: account for tokenization differences in RoBERTa Spanish monolinguals  by\n",
    "            #.      adding a whitespace in front of the target word (otherwise, the function\n",
    "            #.      `find_sublist_index` will not be able to identify the target token-s within\n",
    "            #.      the tokenized sentence)\n",
    "            \n",
    "            if mpath in [\"FacebookAI/roberta-large\", \"FacebookAI/roberta-base\"]:\n",
    "                target = \" {w}\".format(w = row['string'])\n",
    "            else:\n",
    "                target = row['string']\n",
    "\n",
    "            s1 = get_embedding(model, tokenizer, row['sentence1'], target,layer, device)\n",
    "            s2 = get_embedding(model, tokenizer, row['sentence2'], target,layer, device)\n",
    "\n",
    "            ### Now calculate cosine distance \n",
    "            #.  note, tensors need to be copied to cpu to make this run;\n",
    "            #.  still faster to do this copy than to just have everything\n",
    "            #.  running on the cpu\n",
    "            if device.type == \"mps\":  \n",
    "                model_cosine = cosine(s1.cpu(), s2.cpu())\n",
    "\n",
    "            else: \n",
    "                model_cosine = cosine(s1, s2)\n",
    "\n",
    "\n",
    "\n",
    "            if row['same'] == True:\n",
    "                same_sense = \"Same Sense\"\n",
    "            else:\n",
    "                same_sense = \"Different Sense\"\n",
    "\n",
    "\n",
    "            ### Figure out how many tokens you're\n",
    "            ### comparing across sentences\n",
    "            n_tokens_s1 = len(tokenizer.encode(row['sentence1']))\n",
    "            n_tokens_s2 = len(tokenizer.encode(row['sentence2']))\n",
    "\n",
    "            ### Add to results dictionary\n",
    "            results.append({\n",
    "                'sentence1': row['sentence1'],\n",
    "                'sentence2': row['sentence2'],\n",
    "                'word': row['word'],\n",
    "                'string': row['string'],\n",
    "                'Same_sense': row['same'],\n",
    "                'Distance': model_cosine,\n",
    "                'Layer': layer,\n",
    "                'S1_ntokens': n_tokens_s1,\n",
    "                'S2_ntokens': n_tokens_s2\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results['token_diffs'] = np.abs(df_results['S1_ntokens'].values-df_results['S2_ntokens'].values)\n",
    "    df_results['n_params'] = np.repeat(n_params,df_results.shape[0])\n",
    "    \n",
    "    \n",
    "    ### Hurray! Save your cosine distance results to load into R\n",
    "    #.  for analysis\n",
    "\n",
    "    savepath = \"../data/processed/models_english/\"\n",
    "    if not os.path.exists(savepath): \n",
    "        os.mkdir(savepath)\n",
    "\n",
    "    if \"/\" in mpath:\n",
    "        filename = \"rawc-distances_model-\" + mpath.split(\"/\")[1] + \".csv\"\n",
    "    else:\n",
    "        filename = \"rawc-distances_model-\" + mpath + \".csv\"\n",
    "\n",
    "    df_results.to_csv(os.path.join(savepath,filename), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f28c642-f203-4df9-92ad-69c1e06b1833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FacebookAI/roberta-base'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52224eec-d081-4046-bf3e-d9e235edc4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
